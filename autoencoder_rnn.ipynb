{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import History\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from keras.engine import training\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Average, LSTM\n",
    "from keras.layers.convolutional import Convolution1D, AveragePooling1D, MaxPooling1D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from typing import Tuple, List\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_encoding(target_32bp, target_20bp):\n",
    "    # one-hot encoding ACGT_32bp\n",
    "\n",
    "    ACGT = [['A'], ['C'], ['G'], ['T']]\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "    onehot_encoder.fit(ACGT)\n",
    "\n",
    "    RNA_encoded_32bp = []\n",
    "\n",
    "    RNA_encoded_20bp = []\n",
    "\n",
    "    target_32bp = np.array(target_32bp)\n",
    "\n",
    "    target_20bp = np.array(target_20bp)\n",
    "\n",
    "    for i in range(len(target_32bp)):\n",
    "        target_32bp_raw = np.array(list(target_32bp[i])).reshape(-1, 1)\n",
    "\n",
    "        target_32bp_encoded = onehot_encoder.transform(target_32bp_raw)\n",
    "\n",
    "        target_20bp_raw = np.array(list(target_20bp[i])).reshape(-1, 1)\n",
    "\n",
    "        target_20bp_encoded = onehot_encoder.transform(target_20bp_raw)\n",
    "\n",
    "        RNA_encoded_32bp.append(target_32bp_encoded)\n",
    "\n",
    "        RNA_encoded_20bp.append(target_20bp_encoded)\n",
    "\n",
    "    return RNA_encoded_32bp, RNA_encoded_20bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_train = pd.read_csv(\"./RNA_train.csv\")\n",
    "RNA_train.describe(include=\"all\")\n",
    "RNA_test = pd.read_csv(\"./RNA_test.csv\")\n",
    "RNA_test.describe(include=\"all\")\n",
    "\n",
    "train_target_50bp = RNA_train.target_50bp\n",
    "train_target_34bp = RNA_train.target_34bp\n",
    "train_target_20bp = RNA_train.target_20bp\n",
    "train_indel = RNA_train.indel\n",
    "\n",
    "test_target_50bp = RNA_test.target_50bp\n",
    "test_target_34bp = RNA_test.target_34bp\n",
    "test_target_20bp = RNA_test.target_20bp\n",
    "test_indel = RNA_test.indel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_encoded_32bp, train_target_encoded_20bp = onehot_encoding(train_target_34bp, train_target_20bp)\n",
    "test_target_encoded_32bp, test_target_encoded_20bp = onehot_encoding(test_target_34bp, test_target_20bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "x_train = train_target_encoded_32bp\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = train_indel\n",
    "y_train = list(y_train)\n",
    "y_train = np.reshape(list(y_train),(-1,1)) \n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split (x_train,y_train,test_size=0.2,random_state=123)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "Y_train = np.array(Y_train)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "\n",
    "x_test = test_target_encoded_32bp\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_test = test_indel\n",
    "y_test2 = list(y_test)\n",
    "y_test = np.reshape(list(y_test2),(-1,1))\n",
    "\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(34, 4))\n",
    "x = Convolution1D(32, 5, padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Convolution1D(16, 5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Convolution1D(1, 5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded = Activation('relu')(x)\n",
    "\n",
    "x = Convolution1D(1, 5, padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Convolution1D(16, 5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Convolution1D(4, 5, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "decoded = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 34, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 34, 32)            672       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 34, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 34, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 34, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 34, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 34, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 34, 1)             81        \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 34, 1)             4         \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 34, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 34, 1)             6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 34, 1)             4         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 34, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 34, 16)            96        \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 34, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 34, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 34, 4)             324       \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 34, 4)             16        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 34, 4)             0         \n",
      "=================================================================\n",
      "Total params: 4,035\n",
      "Trainable params: 3,895\n",
      "Non-trainable params: 140\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\jongjin\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\jongjin\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/300\n",
      "12000/12000 [==============================] - 9s 782us/step - loss: 0.3116 - val_loss: 0.2219\n",
      "Epoch 2/300\n",
      "12000/12000 [==============================] - 4s 298us/step - loss: 0.1032 - val_loss: 0.0772\n",
      "Epoch 3/300\n",
      "12000/12000 [==============================] - 4s 353us/step - loss: 0.0408 - val_loss: 0.0344\n",
      "Epoch 4/300\n",
      "12000/12000 [==============================] - 4s 335us/step - loss: 0.0308 - val_loss: 0.0280\n",
      "Epoch 5/300\n",
      "12000/12000 [==============================] - 4s 324us/step - loss: 0.0259 - val_loss: 0.0234\n",
      "Epoch 6/300\n",
      "12000/12000 [==============================] - 4s 323us/step - loss: 0.0228 - val_loss: 0.0212\n",
      "Epoch 7/300\n",
      "12000/12000 [==============================] - 4s 326us/step - loss: 0.0207 - val_loss: 0.0194\n",
      "Epoch 8/300\n",
      "12000/12000 [==============================] - 4s 328us/step - loss: 0.0191 - val_loss: 0.0181\n",
      "Epoch 9/300\n",
      "12000/12000 [==============================] - 4s 333us/step - loss: 0.0177 - val_loss: 0.0178\n",
      "Epoch 10/300\n",
      "12000/12000 [==============================] - 4s 324us/step - loss: 0.0164 - val_loss: 0.0162\n",
      "Epoch 11/300\n",
      "12000/12000 [==============================] - 4s 324us/step - loss: 0.0157 - val_loss: 0.0145\n",
      "Epoch 12/300\n",
      "12000/12000 [==============================] - 4s 329us/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 13/300\n",
      "12000/12000 [==============================] - 4s 331us/step - loss: 0.0135 - val_loss: 0.0128\n",
      "Epoch 14/300\n",
      "12000/12000 [==============================] - 4s 326us/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 15/300\n",
      "12000/12000 [==============================] - 4s 326us/step - loss: 0.0126 - val_loss: 0.0140\n",
      "Epoch 16/300\n",
      "12000/12000 [==============================] - 4s 328us/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 17/300\n",
      "12000/12000 [==============================] - 4s 329us/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 18/300\n",
      "12000/12000 [==============================] - 4s 343us/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 19/300\n",
      "12000/12000 [==============================] - 4s 330us/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 20/300\n",
      "12000/12000 [==============================] - 4s 331us/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 21/300\n",
      "12000/12000 [==============================] - 4s 333us/step - loss: 0.0094 - val_loss: 0.0091\n",
      "Epoch 22/300\n",
      "12000/12000 [==============================] - 4s 333us/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 23/300\n",
      "12000/12000 [==============================] - 4s 334us/step - loss: 0.0088 - val_loss: 0.0089\n",
      "Epoch 24/300\n",
      "12000/12000 [==============================] - 4s 331us/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 25/300\n",
      "12000/12000 [==============================] - 4s 338us/step - loss: 0.0081 - val_loss: 0.0072\n",
      "Epoch 26/300\n",
      "12000/12000 [==============================] - 4s 337us/step - loss: 0.0081 - val_loss: 0.0076\n",
      "Epoch 27/300\n",
      "12000/12000 [==============================] - 4s 337us/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 28/300\n",
      "12000/12000 [==============================] - 4s 335us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Epoch 29/300\n",
      "12000/12000 [==============================] - 4s 341us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 30/300\n",
      "12000/12000 [==============================] - 4s 340us/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 31/300\n",
      "12000/12000 [==============================] - 4s 340us/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 32/300\n",
      "12000/12000 [==============================] - 4s 357us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 33/300\n",
      "12000/12000 [==============================] - 4s 352us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 34/300\n",
      "12000/12000 [==============================] - 4s 372us/step - loss: 0.0051 - val_loss: 0.0045\n",
      "Epoch 35/300\n",
      "12000/12000 [==============================] - 5s 457us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 36/300\n",
      "12000/12000 [==============================] - 5s 445us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 37/300\n",
      "12000/12000 [==============================] - 5s 449us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 38/300\n",
      "12000/12000 [==============================] - 5s 451us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 39/300\n",
      "12000/12000 [==============================] - 5s 443us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 40/300\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 41/300\n",
      "12000/12000 [==============================] - 4s 357us/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 42/300\n",
      "12000/12000 [==============================] - 4s 348us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 43/300\n",
      "12000/12000 [==============================] - 4s 344us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 44/300\n",
      "12000/12000 [==============================] - 5s 420us/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 45/300\n",
      "12000/12000 [==============================] - 4s 370us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 46/300\n",
      "12000/12000 [==============================] - 4s 357us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 47/300\n",
      "12000/12000 [==============================] - 4s 352us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 48/300\n",
      "12000/12000 [==============================] - 4s 353us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 49/300\n",
      "12000/12000 [==============================] - 4s 371us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 50/300\n",
      "12000/12000 [==============================] - 4s 352us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 51/300\n",
      "12000/12000 [==============================] - 4s 351us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 52/300\n",
      "12000/12000 [==============================] - 4s 353us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 53/300\n",
      "12000/12000 [==============================] - 4s 365us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 54/300\n",
      "12000/12000 [==============================] - 4s 350us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 55/300\n",
      "12000/12000 [==============================] - 4s 358us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 56/300\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 57/300\n",
      "12000/12000 [==============================] - 5s 376us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 58/300\n",
      "12000/12000 [==============================] - 5s 380us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 59/300\n",
      "12000/12000 [==============================] - 5s 397us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 60/300\n",
      "12000/12000 [==============================] - 5s 409us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 61/300\n",
      "12000/12000 [==============================] - 5s 436us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 62/300\n",
      "12000/12000 [==============================] - 5s 431us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 63/300\n",
      "12000/12000 [==============================] - 5s 402us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 64/300\n",
      "12000/12000 [==============================] - 5s 392us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 65/300\n",
      "12000/12000 [==============================] - 4s 372us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 66/300\n",
      "12000/12000 [==============================] - 4s 367us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 67/300\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 68/300\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 69/300\n",
      "12000/12000 [==============================] - 4s 347us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 70/300\n",
      "12000/12000 [==============================] - 4s 370us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 71/300\n",
      "12000/12000 [==============================] - 4s 336us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 72/300\n",
      "12000/12000 [==============================] - 4s 333us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 73/300\n",
      "12000/12000 [==============================] - 4s 332us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 74/300\n",
      "12000/12000 [==============================] - 4s 336us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 75/300\n",
      "12000/12000 [==============================] - 4s 348us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 76/300\n",
      "12000/12000 [==============================] - 4s 340us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 77/300\n",
      "12000/12000 [==============================] - 4s 339us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 78/300\n",
      "12000/12000 [==============================] - 4s 338us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 79/300\n",
      "12000/12000 [==============================] - 4s 341us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 80/300\n",
      "12000/12000 [==============================] - 4s 340us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 81/300\n",
      "12000/12000 [==============================] - 4s 339us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 82/300\n",
      "12000/12000 [==============================] - 4s 342us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 83/300\n",
      "12000/12000 [==============================] - 4s 343us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 84/300\n",
      "12000/12000 [==============================] - 4s 357us/step - loss: 0.0015 - val_loss: 9.2513e-04\n",
      "Epoch 85/300\n",
      "12000/12000 [==============================] - 4s 362us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 86/300\n",
      "12000/12000 [==============================] - 4s 369us/step - loss: 0.0015 - val_loss: 9.4083e-04\n",
      "Epoch 87/300\n",
      "12000/12000 [==============================] - 4s 370us/step - loss: 0.0015 - val_loss: 9.3555e-04\n",
      "Epoch 88/300\n",
      "12000/12000 [==============================] - 5s 381us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 89/300\n",
      "12000/12000 [==============================] - 5s 400us/step - loss: 0.0018 - val_loss: 0.0019A: 0s - loss\n",
      "Epoch 90/300\n",
      "12000/12000 [==============================] - 5s 392us/step - loss: 0.0016 - val_loss: 0.0085\n",
      "Epoch 91/300\n",
      "12000/12000 [==============================] - 5s 391us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 92/300\n",
      "12000/12000 [==============================] - 5s 385us/step - loss: 0.0014 - val_loss: 9.0356e-04\n",
      "Epoch 93/300\n",
      "12000/12000 [==============================] - 5s 408us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 94/300\n",
      "12000/12000 [==============================] - 4s 371us/step - loss: 0.0014 - val_loss: 9.2144e-04\n",
      "Epoch 95/300\n",
      "12000/12000 [==============================] - 4s 367us/step - loss: 0.0016 - val_loss: 9.2973e-04\n",
      "Epoch 96/300\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.0014 - val_loss: 8.6952e-04\n",
      "Epoch 97/300\n",
      "12000/12000 [==============================] - 4s 353us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 98/300\n",
      "12000/12000 [==============================] - 4s 351us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 99/300\n",
      "12000/12000 [==============================] - 4s 358us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 100/300\n",
      "12000/12000 [==============================] - 4s 357us/step - loss: 0.0014 - val_loss: 8.3438e-04\n",
      "Epoch 101/300\n",
      "12000/12000 [==============================] - 4s 359us/step - loss: 0.0014 - val_loss: 8.1929e-04\n",
      "Epoch 102/300\n",
      "12000/12000 [==============================] - 4s 360us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 103/300\n",
      "12000/12000 [==============================] - 4s 361us/step - loss: 0.0014 - val_loss: 8.2253e-04\n",
      "Epoch 104/300\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.0013 - val_loss: 9.3919e-04\n",
      "Epoch 105/300\n",
      "12000/12000 [==============================] - 4s 364us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 106/300\n",
      "12000/12000 [==============================] - 4s 369us/step - loss: 0.0013 - val_loss: 7.9286e-04\n",
      "Epoch 107/300\n",
      "12000/12000 [==============================] - 4s 367us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 108/300\n",
      "12000/12000 [==============================] - 4s 366us/step - loss: 0.0013 - val_loss: 7.2515e-04\n",
      "Epoch 109/300\n",
      "12000/12000 [==============================] - 4s 368us/step - loss: 0.0013 - val_loss: 8.4601e-04\n",
      "Epoch 110/300\n",
      "12000/12000 [==============================] - 4s 369us/step - loss: 0.0012 - val_loss: 8.4982e-04\n",
      "Epoch 111/300\n",
      "12000/12000 [==============================] - 5s 385us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 112/300\n",
      "12000/12000 [==============================] - 5s 390us/step - loss: 0.0012 - val_loss: 9.6173e-04\n",
      "Epoch 113/300\n",
      "12000/12000 [==============================] - 5s 401us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 114/300\n",
      "12000/12000 [==============================] - 5s 427us/step - loss: 0.0013 - val_loss: 8.7631e-04\n",
      "Epoch 115/300\n",
      "12000/12000 [==============================] - 5s 413us/step - loss: 0.0012 - val_loss: 7.5501e-04\n",
      "Epoch 116/300\n",
      "12000/12000 [==============================] - 5s 419us/step - loss: 0.0013 - val_loss: 7.9296e-04\n",
      "Epoch 117/300\n",
      "12000/12000 [==============================] - 5s 432us/step - loss: 0.0012 - val_loss: 8.4526e-04\n",
      "Epoch 118/300\n",
      "12000/12000 [==============================] - 5s 433us/step - loss: 0.0013 - val_loss: 9.7150e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, X_val),\n",
    "                    callbacks=[early_stopping],\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[6.1624417e-09 6.3294691e-12 1.0000000e+00 4.8972091e-14]\n",
      "  [9.9999928e-01 4.9282767e-07 1.8135848e-08 2.0014539e-07]\n",
      "  [8.8406099e-22 1.0000000e+00 2.0085832e-15 9.5419889e-17]\n",
      "  ...\n",
      "  [3.6434391e-20 1.0000000e+00 4.2391399e-12 4.0327781e-14]\n",
      "  [1.0000000e+00 1.3379012e-10 1.4376600e-10 3.6421220e-11]\n",
      "  [3.3130631e-04 9.9963307e-01 3.7467622e-14 3.5656001e-05]]\n",
      "\n",
      " [[1.5722836e-09 1.0000000e+00 5.4992821e-13 2.8807980e-15]\n",
      "  [3.4585090e-14 6.5604721e-13 4.1952860e-12 1.0000000e+00]\n",
      "  [2.9497202e-16 2.5515237e-16 1.0000000e+00 1.9353614e-14]\n",
      "  ...\n",
      "  [2.8841376e-12 3.6873843e-08 9.9999738e-01 2.6380385e-06]\n",
      "  [1.3539264e-23 1.0000000e+00 9.6894779e-25 2.5163812e-21]\n",
      "  [9.9993145e-01 2.2072207e-05 4.6343077e-05 1.7094364e-07]]\n",
      "\n",
      " [[3.3310639e-07 3.0333049e-06 1.1926802e-08 9.9999666e-01]\n",
      "  [4.4888970e-13 5.3099199e-11 1.0000000e+00 1.2034337e-11]\n",
      "  [4.1255608e-15 1.0000000e+00 6.1743481e-09 6.1563563e-09]\n",
      "  ...\n",
      "  [9.1449740e-28 1.0000000e+00 1.6922856e-17 1.4569442e-18]\n",
      "  [2.1491772e-19 1.0000000e+00 5.4510369e-20 6.8221795e-12]\n",
      "  [5.5455307e-10 1.0000000e+00 1.4162371e-15 4.3582143e-20]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[3.2294926e-07 4.6755943e-11 9.9999964e-01 1.1906307e-09]\n",
      "  [3.8319521e-11 4.1426865e-08 1.0000000e+00 5.3197205e-08]\n",
      "  [1.0000000e+00 5.4234633e-08 3.0859084e-08 3.1207941e-09]\n",
      "  ...\n",
      "  [9.4823958e-12 1.0000000e+00 4.4479148e-15 2.0066324e-13]\n",
      "  [2.1470584e-12 2.4775167e-12 2.8333472e-10 1.0000000e+00]\n",
      "  [7.6752730e-07 1.1010690e-06 9.9989474e-01 1.0335037e-04]]\n",
      "\n",
      " [[9.9937040e-01 5.5133784e-04 7.8253630e-05 1.0804520e-10]\n",
      "  [9.9999893e-01 4.4211495e-07 1.0388825e-08 5.9210964e-07]\n",
      "  [7.1080592e-19 1.0000000e+00 2.6468254e-17 4.1706931e-21]\n",
      "  ...\n",
      "  [8.0609821e-09 4.0178474e-09 1.0000000e+00 4.1259093e-14]\n",
      "  [1.3194105e-12 5.0491541e-15 1.0000000e+00 7.3734757e-10]\n",
      "  [8.9321492e-07 1.5631298e-02 2.9792465e-04 9.8406982e-01]]\n",
      "\n",
      " [[1.3879394e-06 9.2538562e-07 6.0764189e-09 9.9999774e-01]\n",
      "  [1.2088732e-12 1.6200163e-12 6.3218472e-06 9.9999368e-01]\n",
      "  [4.0984056e-09 2.5159991e-12 1.0000000e+00 2.5788706e-11]\n",
      "  ...\n",
      "  [9.9999988e-01 1.7557245e-07 4.3619075e-12 1.1796349e-11]\n",
      "  [1.4406826e-09 1.8063749e-07 1.4528796e-09 9.9999976e-01]\n",
      "  [3.3630033e-05 3.2683998e-05 9.9601376e-01 3.9198925e-03]]]\n"
     ]
    }
   ],
   "source": [
    "decoded_squence = autoencoder.predict(x_test)\n",
    "ary_decoded = decoded_squence\n",
    "ary_test = x_test\n",
    "print(decoded_squence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "len = ary_decoded.shape[0]\n",
    "print(len)\n",
    "sequence_len = ary_decoded.shape[1]\n",
    "print(sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987858920658048\n"
     ]
    }
   ],
   "source": [
    "for i in range(len):\n",
    "    for j in range(sequence_len):\n",
    "        maxx = np.where(max(ary_decoded[i][j]) == ary_decoded[i][j])[0][0]\n",
    "        for k in range(4):\n",
    "            if k==maxx :\n",
    "                ary_decoded[i][j][k]=1\n",
    "            else :\n",
    "                ary_decoded[i][j][k]=0\n",
    "\n",
    "ary_decoded = np.reshape(ary_decoded, (-1))\n",
    "ary_test = np.reshape(x_test, (-1))\n",
    "corrr = np.corrcoef(ary_decoded, ary_test)\n",
    "print(corrr[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(1292) :\n",
    "    if ary_decoded[i]!=ary_test[i] :\n",
    "        cnt = cnt + 1\n",
    "        \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_img, encoded)\n",
    "encoder.save('encoder_34.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encoder.predict(X_train)\n",
    "encoded_val = encoder.predict(X_val)\n",
    "encoded_test = encoder.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 66,689\n",
      "Trainable params: 66,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(34,1,)))\n",
    "model.add(Dropout(0,2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/100\n",
      "12000/12000 [==============================] - 7s 570us/step - loss: 0.0590 - val_loss: 0.0586\n",
      "Epoch 2/100\n",
      "12000/12000 [==============================] - 7s 543us/step - loss: 0.0587 - val_loss: 0.0613\n",
      "Epoch 3/100\n",
      "12000/12000 [==============================] - 7s 550us/step - loss: 0.0587 - val_loss: 0.0591\n",
      "Epoch 4/100\n",
      "12000/12000 [==============================] - 7s 553us/step - loss: 0.0582 - val_loss: 0.0625\n",
      "Epoch 5/100\n",
      "12000/12000 [==============================] - 7s 555us/step - loss: 0.0586 - val_loss: 0.0570\n",
      "Epoch 6/100\n",
      "12000/12000 [==============================] - 7s 574us/step - loss: 0.0579 - val_loss: 0.0568\n",
      "Epoch 7/100\n",
      "12000/12000 [==============================] - 7s 578us/step - loss: 0.0571 - val_loss: 0.0562\n",
      "Epoch 8/100\n",
      "12000/12000 [==============================] - 7s 588us/step - loss: 0.0565 - val_loss: 0.0568\n",
      "Epoch 9/100\n",
      "12000/12000 [==============================] - 7s 603us/step - loss: 0.0569 - val_loss: 0.0566\n",
      "Epoch 10/100\n",
      "12000/12000 [==============================] - 8s 625us/step - loss: 0.0560 - val_loss: 0.0558\n",
      "Epoch 11/100\n",
      "12000/12000 [==============================] - 8s 650us/step - loss: 0.0563 - val_loss: 0.0582\n",
      "Epoch 12/100\n",
      "12000/12000 [==============================] - 8s 696us/step - loss: 0.0560 - val_loss: 0.0572\n",
      "Epoch 13/100\n",
      "12000/12000 [==============================] - 8s 667us/step - loss: 0.0554 - val_loss: 0.0551\n",
      "Epoch 14/100\n",
      "12000/12000 [==============================] - 8s 626us/step - loss: 0.0552 - val_loss: 0.0607\n",
      "Epoch 15/100\n",
      "12000/12000 [==============================] - 7s 568us/step - loss: 0.0553 - val_loss: 0.0555\n",
      "Epoch 16/100\n",
      "12000/12000 [==============================] - 6s 523us/step - loss: 0.0552 - val_loss: 0.0547\n",
      "Epoch 17/100\n",
      "12000/12000 [==============================] - 7s 563us/step - loss: 0.0547 - val_loss: 0.0578\n",
      "Epoch 18/100\n",
      "12000/12000 [==============================] - 7s 555us/step - loss: 0.0545 - val_loss: 0.0547\n",
      "Epoch 19/100\n",
      "12000/12000 [==============================] - 7s 546us/step - loss: 0.0536 - val_loss: 0.0545\n",
      "Epoch 20/100\n",
      "12000/12000 [==============================] - 7s 552us/step - loss: 0.0539 - val_loss: 0.0565\n",
      "Epoch 21/100\n",
      "12000/12000 [==============================] - 7s 578us/step - loss: 0.0541 - val_loss: 0.0543\n",
      "Epoch 22/100\n",
      "12000/12000 [==============================] - 7s 563us/step - loss: 0.0540 - val_loss: 0.0541\n",
      "Epoch 23/100\n",
      "12000/12000 [==============================] - 7s 558us/step - loss: 0.0540 - val_loss: 0.0551\n",
      "Epoch 24/100\n",
      "12000/12000 [==============================] - 7s 566us/step - loss: 0.0532 - val_loss: 0.0532\n",
      "Epoch 25/100\n",
      "12000/12000 [==============================] - 7s 578us/step - loss: 0.0526 - val_loss: 0.0546\n",
      "Epoch 26/100\n",
      "12000/12000 [==============================] - 7s 579us/step - loss: 0.0527 - val_loss: 0.0538\n",
      "Epoch 27/100\n",
      "12000/12000 [==============================] - 7s 593us/step - loss: 0.0528 - val_loss: 0.0530\n",
      "Epoch 28/100\n",
      "12000/12000 [==============================] - 7s 606us/step - loss: 0.0525 - val_loss: 0.0554\n",
      "Epoch 29/100\n",
      "12000/12000 [==============================] - 8s 627us/step - loss: 0.0528 - val_loss: 0.0534\n",
      "Epoch 30/100\n",
      "12000/12000 [==============================] - 8s 658us/step - loss: 0.0525 - val_loss: 0.0529\n",
      "Epoch 31/100\n",
      "12000/12000 [==============================] - 8s 697us/step - loss: 0.0525 - val_loss: 0.0538\n",
      "Epoch 32/100\n",
      "12000/12000 [==============================] - 8s 697us/step - loss: 0.0520 - val_loss: 0.0541\n",
      "Epoch 33/100\n",
      "12000/12000 [==============================] - 8s 647us/step - loss: 0.0520 - val_loss: 0.0540\n",
      "Epoch 34/100\n",
      "12000/12000 [==============================] - 8s 682us/step - loss: 0.0523 - val_loss: 0.0531\n",
      "Epoch 35/100\n",
      "12000/12000 [==============================] - 7s 597us/step - loss: 0.0522 - val_loss: 0.0527\n",
      "Epoch 36/100\n",
      "12000/12000 [==============================] - 7s 559us/step - loss: 0.0517 - val_loss: 0.0526\n",
      "Epoch 37/100\n",
      "12000/12000 [==============================] - 7s 551us/step - loss: 0.0514 - val_loss: 0.0535\n",
      "Epoch 38/100\n",
      "12000/12000 [==============================] - 7s 550us/step - loss: 0.0514 - val_loss: 0.0530\n",
      "Epoch 39/100\n",
      "12000/12000 [==============================] - 7s 560us/step - loss: 0.0511 - val_loss: 0.0526\n",
      "Epoch 40/100\n",
      "12000/12000 [==============================] - 7s 555us/step - loss: 0.0511 - val_loss: 0.0531\n",
      "Epoch 41/100\n",
      "12000/12000 [==============================] - 7s 554us/step - loss: 0.0509 - val_loss: 0.0530\n",
      "Epoch 42/100\n",
      "12000/12000 [==============================] - 7s 560us/step - loss: 0.0508 - val_loss: 0.0537\n",
      "Epoch 43/100\n",
      "12000/12000 [==============================] - 7s 559us/step - loss: 0.0511 - val_loss: 0.0531\n",
      "Epoch 44/100\n",
      "12000/12000 [==============================] - 7s 569us/step - loss: 0.0505 - val_loss: 0.0522\n",
      "Epoch 45/100\n",
      "12000/12000 [==============================] - 7s 576us/step - loss: 0.0505 - val_loss: 0.0531\n",
      "Epoch 46/100\n",
      "12000/12000 [==============================] - 7s 580us/step - loss: 0.0503 - val_loss: 0.0546\n",
      "Epoch 47/100\n",
      "12000/12000 [==============================] - 7s 592us/step - loss: 0.0498 - val_loss: 0.0525\n",
      "Epoch 48/100\n",
      "12000/12000 [==============================] - 7s 608us/step - loss: 0.0500 - val_loss: 0.0532\n",
      "Epoch 49/100\n",
      "12000/12000 [==============================] - 8s 632us/step - loss: 0.0504 - val_loss: 0.0532\n",
      "Epoch 50/100\n",
      "12000/12000 [==============================] - 8s 669us/step - loss: 0.0499 - val_loss: 0.0528\n",
      "Epoch 51/100\n",
      "12000/12000 [==============================] - 8s 693us/step - loss: 0.0494 - val_loss: 0.0534\n",
      "Epoch 52/100\n",
      "12000/12000 [==============================] - 9s 765us/step - loss: 0.0505 - val_loss: 0.0532\n",
      "Epoch 53/100\n",
      "12000/12000 [==============================] - 9s 726us/step - loss: 0.0490 - val_loss: 0.0533\n",
      "Epoch 54/100\n",
      "12000/12000 [==============================] - 8s 646us/step - loss: 0.0490 - val_loss: 0.0547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2401766bb38>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience = 10)\n",
    "\n",
    "model.fit(encoded_train, Y_train, epochs=100, batch_size=128, validation_data=(encoded_val, Y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1265777  -0.00561314  0.17285797 ...  0.6206628   0.5707806\n",
      "  0.65318793]\n"
     ]
    }
   ],
   "source": [
    "predict_model = model.predict(encoded_test, batch_size=50, verbose=0)\n",
    "predict_model = predict_model.flatten()\n",
    "\n",
    "print(predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "0  1.000000  0.693779\n",
      "1  0.693779  1.000000\n"
     ]
    }
   ],
   "source": [
    "list_y_test = y_test2\n",
    "list_y_predict = predict_model\n",
    "\n",
    "com_list = np.stack([list_y_test, list_y_predict])\n",
    "\n",
    "df = pd.DataFrame(com_list).T\n",
    "corr = df.corr(method = 'spearman')\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
